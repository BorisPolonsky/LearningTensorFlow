{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generator based on RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief\n",
    "Generate fake abstract with RNN model under tensorflow r1.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = (\" $%'()+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "            \"\\\\^_abcdefghijklmnopqrstuvwxyz{|}\\n\")\n",
    "graph_path = r\"./graphs\"\n",
    "test_text_path = os.path.normpath(r\"../Dataset/arvix_abstracts.txt\")\n",
    "batch_size=50\n",
    "model_param_path=os.path.normpath(r\"./model_checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data encoding\n",
    "#### Basic Assumption\n",
    "\n",
    "* A full string sequence consists $START$ & $STOP$ signal with characters in the middle. \n",
    "\n",
    "#### Encoding policy\n",
    "* A set $\\mathcal{S}$ that consists of many characters is utilized to encode the characters.\n",
    "* The $1^{st}$ entry of the vector corresponds to $UNKNOWN$ characters(l.e. characters that are beyond $\\mathcal{S}$). \n",
    "* The last entry of the vector corresponds to $STOP$ signal of the sequence. \n",
    "* The entries in the middle corresponds to the indices of the characters within $\\mathcal{S}$. \n",
    "* The $START$ signal is represented as a zero vector. \n",
    "\n",
    "#### Implementation & Test\n",
    "##### Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCodec:\n",
    "    def __init__(self, vocab):\n",
    "        self._vocab = vocab\n",
    "        self._dim = len(vocab) + 2\n",
    "\n",
    "    def encode(self, string, sess = None, start=True, stop=True):\n",
    "        \"\"\"\n",
    "        Encode string.\n",
    "        Each character is represented as a N-dimension one hot vector. \n",
    "        N = len(self._vocab)+ 2\n",
    "        \n",
    "        Note:\n",
    "        The first entry of the vector corresponds to unknown character. \n",
    "        The last entry of the vector corresponds to STOP signal of the sequence. \n",
    "        The entries in the middle corresponds to the index of the character. \n",
    "        The START signal is represented as a zero vector. \n",
    "        \"\"\"\n",
    "        tensor = [vocab.find(ch) + 1 for ch in string]\n",
    "        if stop:\n",
    "             tensor.append(len(vocab)+1)  # String + STOP\n",
    "        tensor = tf.one_hot(tensor,depth=len(vocab) + 2,on_value=1.0,off_value=0.0,axis=-1, dtype=tf.float32)\n",
    "        if start:\n",
    "            tensor=tf.concat([tf.zeros([1, len(vocab) + 2],dtype=tf.float32),tensor],axis=0)  # String + START\n",
    "        if sess is None:\n",
    "            with tf.Session() as sess:\n",
    "                nparray=tensor.eval()\n",
    "        elif type(sess) == tf.Session:\n",
    "            nparray = tensor.eval(session=sess)\n",
    "        else:\n",
    "            raise TypeError('\"sess\" must be {}, got {}'.format(tf.Session, type(sess)))    \n",
    "        return nparray\n",
    "\n",
    "    def decode(self, nparray, default=\"[UNKNOWN]\",start=\"[START]\",stop=\"[STOP]\",strip=False):\n",
    "        text_list = []\n",
    "        indices=np.argmax(nparray,axis=1)\n",
    "        for v, ch_i in zip(nparray,indices):\n",
    "            if np.all(v==0):\n",
    "                text_list.append(start if not strip else \"\")\n",
    "            elif ch_i==0:\n",
    "                text_list.append(default)\n",
    "            elif ch_i==len(self._vocab)+1:\n",
    "                text_list.append(stop if not strip else \"\")\n",
    "            else:\n",
    "                text_list.append(vocab[ch_i-1])\n",
    "        return \"\".join(text_list)\n",
    "    \n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self._dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test\n",
    "See how encoding and decoding work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_codec=TextCodec(vocab)\n",
    "test_text_encoded=test_codec.encode(\"Hello world!\")\n",
    "print(\"Encoded text looks like:\\n{}\".format(test_text_encoded))\n",
    "test_text_decoded=test_codec.decode(nparray=test_text_encoded,strip=False)\n",
    "print(\"Decoded text looks like:\\n{}\".format(test_text_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(test_text_path, \"r\") as f:\n",
    "    raw_text_list = \"\".join(f.readlines()).split(\"\\n\")\n",
    "print(\"Loaded abstract from a total of {} theses.\".format(len(raw_text_list)))\n",
    "# See what we have loaded\n",
    "sample_text_no = random.randint(0, len(raw_text_list)-1)\n",
    "sample_text_raw = raw_text_list[sample_text_no]\n",
    "print(\"A sample text in the data set:\\n{}\".format(sample_text_raw))\n",
    "sample_text_encoded=test_codec.encode(sample_text_raw)\n",
    "print(\"Encoded text:\\n{}\".format(sample_text_encoded))\n",
    "print(\"Decoded text:\\n{}\".format(test_codec.decode(sample_text_encoded)))\n",
    "encoded_data = test_codec.encode(\"\\n\".join(raw_text_list), start=False, stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data, codec, batch_size, seq_length, reset_every):\n",
    "    if type(data) == str:\n",
    "        data=codec.encode(data, start=False, stop=False)\n",
    "    head = 0\n",
    "    reset_index = 0\n",
    "    batch = []\n",
    "    seq = []\n",
    "    increment = seq_length * reset_every - 1\n",
    "    extras = codec.encode(\"\", start=True, stop=True)\n",
    "    v_start, v_stop = extras[0: 1, :], extras[1: 2, :]\n",
    "    while head < np.shape(data)[0] or len(batch) == batch_size:\n",
    "        if len(batch) == batch_size:\n",
    "            batch = np.array(batch)\n",
    "            for offset in range(reset_every):\n",
    "                yield (batch[:, offset * seq_length: (offset + 1) * seq_length, :], \n",
    "                batch[:, offset * seq_length + 1: (offset + 1) * seq_length + 1, :])\n",
    "            batch = []\n",
    "        else:\n",
    "            seq = np.concatenate([v_start, data[head: head + increment, :], v_stop], axis=0)\n",
    "            if np.shape(seq)[0] == (increment + 2):\n",
    "                batch.append(seq)\n",
    "            head += increment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "reset_every = 2\n",
    "batch_size = 2\n",
    "batches = batch_generator(data=encoded_data, \n",
    "                               codec=test_codec, \n",
    "                               batch_size=batch_size, \n",
    "                               seq_length=seq_length, \n",
    "                               reset_every=reset_every)\n",
    "for (x, y), i in zip(batches, range(reset_every * 2)):\n",
    "    print(\"Batch {}\".format(i))\n",
    "    if (i % reset_every) == 0:\n",
    "        print(\"Reset\")\n",
    "    for j in range(batch_size):\n",
    "        decoded_x, decoded_y = test_codec.decode(x[j], strip=False), test_codec.decode(y[j], strip=False)\n",
    "        print(\"Index of sub-sequence:\\n{}\\nSequence input:\\n{}:\\nSequence output:\\n{}\".format(j, \n",
    "                                                                                          decoded_x, \n",
    "                                                                                          decoded_y))\n",
    "del seq_length, reset_every, batch_size, batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRNN(tf.nn.rnn_cell.RNNCell):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_hidden_layer, dtype=tf.float32):\n",
    "        super(tf.nn.rnn_cell.RNNCell, self).__init__(dtype=dtype)\n",
    "        assert type(input_dim) == int and input_dim > 0, \"Invalid input dimension. \"\n",
    "        self._input_dim = input_dim\n",
    "        assert type(num_hidden_layer) == int and num_hidden_layer > 0, \"Invalid number of hidden layer. \"\n",
    "        self._num_hidden_layer = num_hidden_layer\n",
    "        assert type(hidden_dim) == int and hidden_dim > 0, \"Invalid dimension of hidden states. \"\n",
    "        self._hidden_dim = hidden_dim\n",
    "        assert type(output_dim) == int and output_dim > 0, \"Invalid dimension of output dimension. \"\n",
    "        self._output_dim = output_dim\n",
    "        self._state_is_tuple = True\n",
    "        with tf.variable_scope(\"input_layer\"):\n",
    "            self._W_xh = tf.get_variable(\"W_xh\", shape=[self._input_dim, self._hidden_dim])\n",
    "            self._b_xh = tf.get_variable(\"b_xh\", shape=[self._hidden_dim])\n",
    "        with tf.variable_scope(\"rnn_layers\"):\n",
    "            self._cells = [tf.nn.rnn_cell.GRUCell(self._hidden_dim) for _ in range(num_hidden_layer)]\n",
    "        with tf.variable_scope(\"output_layer\"):\n",
    "            self._W_ho_list = [tf.get_variable(\"W_h{}o\".format(i), shape=[self._hidden_dim, self._output_dim])\n",
    "                               for i in range(num_hidden_layer)]\n",
    "            self._b_ho = tf.get_variable(\"b_ho\", shape=[self._output_dim])\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._output_dim\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return (self._hidden_dim,) * self._num_hidden_layer\n",
    "\n",
    "    def zero_state(self, batch_size, dtype):\n",
    "        if self._state_is_tuple:\n",
    "            return tuple(cell.zero_state(batch_size, dtype)for cell in self._cells)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Not implemented yet.\")\n",
    "\n",
    "    def __call__(self, _input, state, scope=None):\n",
    "        assert type(state) == tuple and len(state) == self._num_hidden_layer, \"state must be a tuple of size {}\".format(\n",
    "            self._num_hidden_layer)\n",
    "        hidden_layer_input = tf.matmul(_input, self._W_xh) + self._b_xh\n",
    "        prev_output = hidden_layer_input\n",
    "        final_state = []\n",
    "        output = None\n",
    "        for hidden_layer_index, hidden_cell in enumerate(self._cells):\n",
    "            with tf.variable_scope(\"cell_{}\".format(hidden_layer_index)):\n",
    "                new_output, new_state = hidden_cell(prev_output, state[hidden_layer_index])\n",
    "                prev_output = new_output + hidden_layer_input  # Should be included in variable scope of this layer or?\n",
    "                final_state.append(new_state)\n",
    "            _W_ho = self._W_ho_list[hidden_layer_index]\n",
    "            if output is None:\n",
    "                output = tf.matmul(new_output, _W_ho)\n",
    "            else:\n",
    "                output = output + tf.matmul(new_output, _W_ho)\n",
    "        output = tf.tanh(output + self._b_ho)\n",
    "        # output = tf.nn.relu(output)\n",
    "        final_state = tuple(final_state)\n",
    "        return output, final_state\n",
    "\n",
    "    def inspect_weights(self, sess):\n",
    "        val = self._W_xh.eval(sess)\n",
    "        print(\"W_xh:\\n{}\\nF-norm:\\n{}\".format(val, norm(val)))\n",
    "        val = self._b_xh.eval(sess)\n",
    "        print(\"b_xh:\\n{}\\nF-norm:\\n{}\".format(val, norm(val)))\n",
    "        for hidden_layer_index in range(self._num_hidden_layer):\n",
    "            val = self._W_ho_list[hidden_layer_index].eval(sess)\n",
    "            print(\"W_h{}o:\\n{}\\nF-norm:\\n{}\".format(hidden_layer_index, val, norm(val)))\n",
    "        val = self._b_ho.eval(sess)\n",
    "        print(\"b_ho:\\n{}\\nF-norm:\\n{}\".format(val, norm(val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an instance of the model and define the rest of the graph\n",
    "#### Thoughts\n",
    "If GRU is used, then the outputs of GRU shall not be directly used as desired output without further transforms. (e.g. A cell accpet 2 inputs, a state from the previous cell and the input of this cell(which is approximated by the state input), then the RNN cell can be treated as a normal feed forward network. \n",
    "\n",
    "**The proposal above is to be tested again due to the previous bug in training (Failed to feed the initial state given by the RNN output from last sequnce)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "input_dim = output_dim = test_codec.dim\n",
    "hidden_dim = 700\n",
    "num_hidden_layer = 3\n",
    "rnn_cell = DRNN(input_dim=input_dim, output_dim=output_dim, num_hidden_layer=num_hidden_layer, hidden_dim=hidden_dim)\n",
    "batch_size = 50\n",
    "init_state = tuple(tf.placeholder_with_default(input=tensor, \n",
    "                                         shape=[None, hidden_dim]) for tensor in rnn_cell.zero_state(\n",
    "    batch_size=batch_size, dtype=tf.float32))\n",
    "seq_input = tf.placeholder(name=\"batch_input\", shape=[None, None, input_dim], dtype=tf.float32)\n",
    "target_seq_output = tf.placeholder(name=\"target_batch_output\", shape=[None, None, output_dim], dtype=tf.float32)\n",
    "seq_output, final_states = tf.nn.dynamic_rnn(cell=rnn_cell,inputs=seq_input, \n",
    "                                                      initial_state=init_state, dtype=tf.float32)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target_seq_output, logits=seq_output))\n",
    "summary_op = tf.summary.scalar(tensor=loss, name=\"loss\")\n",
    "global_step = tf.get_variable(name=\"global_step\", initializer=0, trainable=False)\n",
    "lr = tf.get_variable(name=\"learning_rate\", initializer=1.0, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epoch=50\n",
    "learning_rate=1e-3\n",
    "train_op=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss, global_step=global_step)\n",
    "print_every = 50\n",
    "save_every = 1000\n",
    "partition_size = 100\n",
    "logdir = os.path.normpath(\"./graphs\")\n",
    "seq_length = 100\n",
    "reset_every = 100\n",
    "learning_rate_decay = 0.9\n",
    "# batch_size has been specified when configuring the the tensors for initial states\n",
    "\n",
    "keep_checkpoint_every_n_hours = 0.5\n",
    "model_checkpoint_path = os.path.normpath(\"./model_checkpoints\")\n",
    "saver = tf.train.Saver(keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)\n",
    "batches = list(batch_generator(data=encoded_data, \n",
    "                               codec=test_codec, \n",
    "                               batch_size=batch_size, \n",
    "                               seq_length=seq_length, \n",
    "                               reset_every=reset_every))\n",
    "with tf.Session() as sess, tf.summary.FileWriter(logdir=logdir) as writer:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    feed_dict = dict()\n",
    "    states = None\n",
    "    sess.run(tf.assign(lr, learning_rate))\n",
    "    for epoch in range(n_epoch):\n",
    "        assert lr.eval(sess) > 0, \"learning_rate must be positive.\"\n",
    "        for i, (x, y) in enumerate(batches):\n",
    "            feed_dict = {seq_input: x, target_seq_output: y}\n",
    "            if (j % reset_every) != 0 and states is not None:\n",
    "                for j in range(len(init_state)):\n",
    "                    feed_dict[init_state[j]] = states[j]\n",
    "            _, summary, states, step = sess.run(fetches=[train_op, summary_op, final_states, global_step], \n",
    "                                                feed_dict=feed_dict)\n",
    "            writer.add_summary(summary=summary, global_step=step)\n",
    "            if ((step + 1) % save_every) == 0:\n",
    "                saver.save(sess=sess, save_path=model_checkpoint_path, global_step=step)\n",
    "        sess.run(tf.assign(lr, lr.eval(sess) * learning_rate_decay))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test online inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_inference():\n",
    "    raise NotImplementedError(\"Not implemented yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
