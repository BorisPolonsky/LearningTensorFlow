{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generator based on RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief\n",
    "Generate fake abstract with RNN model under tensorflow r1.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = (\" $%'()+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "            \"\\\\^_abcdefghijklmnopqrstuvwxyz{|}\\n\")\n",
    "graph_path = r\"./graphs\"\n",
    "test_text_path = os.path.normpath(r\"../Dataset/arvix_abstracts.txt\")\n",
    "batch_size=50\n",
    "model_param_path=os.path.normpath(r\"./model_checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data encoding\n",
    "#### Basic Assumption\n",
    "\n",
    "* A full string sequence consists $START$ & $STOP$ signal with characters in the middle. \n",
    "\n",
    "#### Encoding policy\n",
    "* A set $\\mathcal{S}$ that consists of many characters is utilized to encode the characters.\n",
    "* The $1^{st}$ entry of the vector corresponds to $UNKNOWN$ characters(l.e. characters that are beyond $\\mathcal{S}$). \n",
    "* The last entry of the vector corresponds to $STOP$ signal of the sequence. \n",
    "* The entries in the middle corresponds to the indices of the characters within $\\mathcal{S}$. \n",
    "* The $START$ signal is represented as a zero vector. \n",
    "\n",
    "#### Implementation & Test\n",
    "##### Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCodec:\n",
    "    def __init__(self, vocab):\n",
    "        self._vocab = vocab\n",
    "        self._dim = len(vocab) + 2\n",
    "\n",
    "    def encode(self, string, sess = None, start=True, stop=True):\n",
    "        \"\"\"\n",
    "        Encode string.\n",
    "        Each character is represented as a N-dimension one hot vector. \n",
    "        N = len(self._vocab)+ 2\n",
    "        \n",
    "        Note:\n",
    "        The first entry of the vector corresponds to unknown character. \n",
    "        The last entry of the vector corresponds to STOP signal of the sequence. \n",
    "        The entries in the middle corresponds to the index of the character. \n",
    "        The START signal is represented as a zero vector. \n",
    "        \"\"\"\n",
    "        tensor=[vocab.find(ch)+1 for ch in string]\n",
    "        if stop:\n",
    "             tensor.append(len(vocab)+1)  # String + STOP\n",
    "        tensor=tf.one_hot(tensor,depth=len(vocab)+2,on_value=1.0,off_value=0.0,axis=-1, dtype=tf.float32)\n",
    "        if start:\n",
    "            tensor=tf.concat([tf.zeros([1, len(vocab)+2],dtype=tf.float32),tensor],axis=0)  # String + START\n",
    "        if sess is None:\n",
    "            with tf.Session() as sess:\n",
    "                nparray=tensor.eval()\n",
    "        elif type(sess) == tf.Session:\n",
    "            nparray = tensor.eval(session=sess)\n",
    "        else:\n",
    "            raise TypeError('\"sess\" must be {}, got {}'.format(tf.Session, type(sess)))    \n",
    "        return nparray\n",
    "\n",
    "    def decode(self, nparray, default=\"[UNKNOWN]\",start=\"[START]\",stop=\"[STOP]\",strip=False):\n",
    "        text_list=[]\n",
    "        indices=np.argmax(nparray,axis=1)\n",
    "        for v, ch_i in zip(nparray,indices):\n",
    "            if np.all(v==0):\n",
    "                text_list.append(start if not strip else \"\")\n",
    "            elif ch_i==0:\n",
    "                text_list.append(default)\n",
    "            elif ch_i==len(self._vocab)+1:\n",
    "                text_list.append(stop if not strip else \"\")\n",
    "            else:\n",
    "                text_list.append(vocab[ch_i-1])\n",
    "        return \"\".join(text_list)\n",
    "    \n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self._dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test\n",
    "See how encoding and decoding work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_codec=TextCodec(vocab)\n",
    "test_text_encoded=test_codec.encode(\"Hello world!\")\n",
    "print(\"Encoded text looks like:\\n{}\".format(test_text_encoded))\n",
    "test_text_decoded=test_codec.decode(nparray=test_text_encoded,strip=False)\n",
    "print(\"Decoded text looks like:\\n{}\".format(test_text_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(test_text_path, \"r\") as f:\n",
    "    raw_text_list = \"\".join(f.readlines()).split(\"\\n\")\n",
    "print(\"Loaded abstract from a total of {} theses.\".format(len(raw_text_list)))\n",
    "# See what we have loaded\n",
    "sample_text_no = random.randint(0, len(raw_text_list)-1)\n",
    "sample_text_raw = raw_text_list[sample_text_no]\n",
    "print(\"A sample text in the data set:\\n{}\".format(sample_text_raw))\n",
    "sample_text_encoded=test_codec.encode(sample_text_raw)\n",
    "print(\"Encoded text:\\n{}\".format(sample_text_encoded))\n",
    "print(\"Decoded text:\\n{}\".format(test_codec.decode(sample_text_encoded)))\n",
    "encoded_data = test_codec.encode(\"\\n\".join(raw_text_list), start=False, stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data, codec, batch_size, seq_length, reset_every):\n",
    "    if type(data) == str:\n",
    "        data=codec.encode(data, start=False, stop=False)\n",
    "    head = 0\n",
    "    reset_index = 0\n",
    "    batch = []\n",
    "    seq = []\n",
    "    while head < np.shape(data)[0]:\n",
    "        if reset_index == 0:\n",
    "            increment = seq_length - 1\n",
    "            seq.append(np.concatenate([codec.encode(\"\", start=True, stop=False), \n",
    "                                    data[head: head + increment, :]], axis=0))\n",
    "        elif reset_index == reset_every - 1:\n",
    "            increment = seq_length - 1\n",
    "            seq.append(np.concatenate([data[head: head + increment], codec.encode(\"\", start=False, stop=True)], axis=0))\n",
    "            batch.append(np.concatenate(seq, axis=0))\n",
    "            seq = []\n",
    "        else:\n",
    "            increment = seq_length\n",
    "            seq.append(data[head: head + increment, :])\n",
    "        reset_index += 1\n",
    "        reset_flag = (reset_index==reset_every)\n",
    "        if len(batch) == batch_size:\n",
    "            mini_batches = np.split(np.array(batch), range(seq_length, seq_length * reset_every, seq_length), axis=1)\n",
    "            for mini_batch in mini_batches:\n",
    "                yield mini_batch\n",
    "            batch = []\n",
    "        head += increment\n",
    "        if reset_flag:\n",
    "            reset_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_length = 100\n",
    "reset_every = 2\n",
    "batch_size = 2\n",
    "batches = batch_generator(data=encoded_data, \n",
    "                               codec=test_codec, \n",
    "                               batch_size=batch_size, \n",
    "                               seq_length=batch_length, \n",
    "                               reset_every=reset_every)\n",
    "for batch, i in zip(batches, range(reset_every * 2)):\n",
    "    print(\"Batch {}\".format(i))\n",
    "    if (i % reset_every) == 0:\n",
    "        print(\"Reset\")\n",
    "    for j, seq in enumerate(batch):\n",
    "        print(\"Sequence {}:\\n{}\".format(j, test_codec.decode(seq, strip=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRNN(tf.nn.rnn_cell.RNNCell):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_hidden_layer, dtype=tf.float32):\n",
    "        super(tf.nn.rnn_cell.RNNCell, self).__init__(dtype=dtype)\n",
    "        assert type(input_dim) == int and input_dim > 0, \"Invalid input dimension. \"\n",
    "        self._input_dim = input_dim\n",
    "        assert type(num_hidden_layer) == int and num_hidden_layer > 0, \"Invalid number of hidden layer. \"\n",
    "        self._num_hidden_layer = num_hidden_layer\n",
    "        assert type(hidden_dim) == int and hidden_dim > 0, \"Invalid dimension of hidden states. \"\n",
    "        self._hidden_dim = hidden_dim\n",
    "        assert type(output_dim) == int and output_dim > 0, \"Invalid dimension of output dimension. \"\n",
    "        self._output_dim = output_dim\n",
    "        self._state_is_tuple = True\n",
    "        with tf.variable_scope(\"input_layer\"):\n",
    "            self._W_xh = tf.get_variable(\"W_xh\", shape=[self._input_dim, self._hidden_dim])\n",
    "            self._b_xh = tf.get_variable(\"b_xh\", shape=[self._hidden_dim])\n",
    "        with tf.variable_scope(\"rnn_layers\"):\n",
    "            self._cells = [tf.nn.rnn_cell.GRUCell(self._hidden_dim) for _ in range(num_hidden_layer)]\n",
    "        with tf.variable_scope(\"output_layer\"):\n",
    "            self._W_ho_list = [tf.get_variable(\"W_h{}o\".format(i), shape=[self._hidden_dim, self._output_dim])\n",
    "                               for i in range(num_hidden_layer)]\n",
    "            self._b_ho = tf.get_variable(\"b_ho\", shape=[self._output_dim])\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._output_dim\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return (self._hidden_dim,) * self._num_hidden_layer\n",
    "\n",
    "    def zero_state(self, batch_size, dtype):\n",
    "        if self._state_is_tuple:\n",
    "            return tuple(cell.zero_state(batch_size, dtype)for cell in self._cells)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Not implemented yet.\")\n",
    "\n",
    "    def __call__(self, _input, state, scope=None):\n",
    "        assert type(state) == tuple and len(state) == self._num_hidden_layer, \"state must be a tuple of size {}\".format(\n",
    "            self._num_hidden_layer)\n",
    "        hidden_layer_input = tf.matmul(_input, self._W_xh) + self._b_xh\n",
    "        prev_output = hidden_layer_input\n",
    "        final_state = []\n",
    "        output = None\n",
    "        for hidden_layer_index, hidden_cell in enumerate(self._cells):\n",
    "            with tf.variable_scope(\"cell_{}\".format(hidden_layer_index)):\n",
    "                new_output, new_state = hidden_cell(prev_output, state[hidden_layer_index])\n",
    "                prev_output = new_output + hidden_layer_input  # Should be included in variable scope of this layer or?\n",
    "                final_state.append(new_state)\n",
    "            _W_ho = self._W_ho_list[hidden_layer_index]\n",
    "            if output is None:\n",
    "                output = tf.matmul(new_output, _W_ho)\n",
    "            else:\n",
    "                output = output + tf.matmul(new_output, _W_ho)\n",
    "        output = tf.tanh(output+self._b_ho)\n",
    "        final_state = tuple(final_state)\n",
    "        return output, final_state\n",
    "\n",
    "    def inspect_weights(self, sess):\n",
    "        val = self._W_xh.eval(sess)\n",
    "        print(\"W_xh:\\n{}\\nF-norm:\\n{}\".format(val, norm(val)))\n",
    "        val = self._b_xh.eval(sess)\n",
    "        print(\"b_xh:\\n{}\\nF-norm:\\n{}\".format(val, norm(val)))\n",
    "        for hidden_layer_index in range(self._num_hidden_layer):\n",
    "            val = self._W_ho_list[hidden_layer_index].eval(sess)\n",
    "            print(\"W_h{}o:\\n{}\\nF-norm:\\n{}\".format(hidden_layer_index, val, norm(val)))\n",
    "        val = self._b_ho.eval(sess)\n",
    "        print(\"b_ho:\\n{}\\nF-norm:\\n{}\".format(val, norm(val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_length = 100\n",
    "reset_every = 100\n",
    "batch_size = 50\n",
    "batches = list(batch_generator(data=encoded_data, \n",
    "                               codec=test_codec, \n",
    "                               batch_size=batch_size, \n",
    "                               seq_length=batch_length, \n",
    "                               reset_every=reset_every))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an instance and define loss function\n",
    "#### Thoughts\n",
    "If GRU is used, then the outputs of GRU shall not be directly used as desired output without further transforms. (e.g. A cell accpet 2 inputs, a state from the previous cell and the input of this cell(which is approximated by the state input), then the RNN cell can be treated as a normal feed forward network. \n",
    "\n",
    "**The proposal above is to be tested again due to the previous bug in training (Failed to feed the initial state given by the RNN output from last sequnce)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "input_dim = output_dim = test_codec.dim\n",
    "hidden_dim = test_codec.dim\n",
    "num_hidden_layer = 3\n",
    "# test_rnn_cell = DRNN(input_dim, hidden_dim, output_dim, num_hidden_layer)\n",
    "test_rnn_cell = tf.nn.rnn_cell.GRUCell(num_units=hidden_dim)\n",
    "init_state = tf.placeholder_with_default(input=test_rnn_cell.zero_state(batch_size=batch_size, dtype=tf.float32),\n",
    "                                         shape=[None, hidden_dim])\n",
    "seq_input = tf.placeholder(shape=[None, input_dim], dtype=tf.float32)\n",
    "batch_seq_input = tf.reshape(tensor=seq_input, shape=[1, -1, input_dim]) #  One sequence in a batch\n",
    "target_seq_output = tf.placeholder(shape=[None, output_dim], dtype=tf.float32)\n",
    "batch_seq_output, batch_seq_state = tf.nn.dynamic_rnn(cell=test_rnn_cell,inputs=batch_seq_input, \n",
    "                                                      initial_state=init_state, dtype=tf.float32)\n",
    "seq_output = tf.squeeze(input=batch_seq_output, axis=[0])\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target_seq_output, logits=seq_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_epoch=2\n",
    "learning_rate=1e-3\n",
    "train_op=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "print_every = 50\n",
    "partition_size = 100\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epoch):\n",
    "        for data_index, data in enumerate(raw_text_list):\n",
    "            data = test_codec.encode(data)\n",
    "            x, y = data[:-1,:], data[1:,:]\n",
    "            x_partitions, y_partitions = partitions(x, partition_size), partitions(y, partition_size)\n",
    "            state = None\n",
    "            for _x, _y in zip(x_partitions, y_partitions):\n",
    "                # print(\"In:\\n{}\\nOut:\\n{}\".format(test_codec.decode(_x), test_codec.decode(_y)))\n",
    "                feed_dict={seq_input: _x, target_seq_output: _y}\n",
    "                if state is not None:\n",
    "                    feed_dict[init_state] = state\n",
    "                _, loss_val, state=sess.run([train_op, loss, batch_seq_state], feed_dict=feed_dict)\n",
    "            if data_index==0 or ((data_index+1) % print_every==0):\n",
    "                print(\"Loss of data number {} at epoch {}:\\n{}\".format(data_index, epoch, loss_val))\n",
    "                print(\"Decoded output given input: {}\".format(\n",
    "                        test_codec.decode(sess.run(seq_output, feed_dict={seq_input: x, target_seq_output: y}))))\n",
    "\n",
    "def online_inference():\n",
    "    raise NotImplementedError(\"Not implemented yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test online inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
