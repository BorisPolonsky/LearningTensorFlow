{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generator based on RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief\n",
    "Generate fake abstract with RNN model under TensorFlow r1.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = (\" $%'()+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "            \"\\\\^_abcdefghijklmnopqrstuvwxyz{|}\\n\")\n",
    "graph_path = r\"./graphs\"\n",
    "test_text_path = os.path.normpath(r\"../Dataset/arvix_abstracts.txt\")\n",
    "batch_size=50\n",
    "model_param_path=os.path.normpath(r\"./model_checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data encoding\n",
    "#### Basic Assumption\n",
    "\n",
    "* A full string sequence consists $START$ & $STOP$ signal with characters in the middle. \n",
    "\n",
    "#### Encoding policy\n",
    "* A set $\\mathcal{S}$ that consists of many characters is utilized to encode the characters.\n",
    "* The $1^{st}$ entry of the vector corresponds to $UNKNOWN$ characters(l.e. characters that are beyond $\\mathcal{S}$). \n",
    "* The last entry of the vector corresponds to $STOP$ signal of the sequence. \n",
    "* The entries in the middle corresponds to the indices of the characters within $\\mathcal{S}$. \n",
    "* The $START$ signal is represented as a zero vector. \n",
    "\n",
    "#### Implementation & Test\n",
    "##### Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCodec:\n",
    "    def __init__(self, vocab):\n",
    "        self._vocab = vocab\n",
    "        self._dim = len(vocab) + 2\n",
    "\n",
    "    def encode(self, string, sess = None, start=True, stop=True):\n",
    "        \"\"\"\n",
    "        Encode string.\n",
    "        Each character is represented as a N-dimension one hot vector. \n",
    "        N = len(self._vocab)+ 2\n",
    "        \n",
    "        Note:\n",
    "        The first entry of the vector corresponds to unknown character. \n",
    "        The last entry of the vector corresponds to STOP signal of the sequence. \n",
    "        The entries in the middle corresponds to the index of the character. \n",
    "        The START signal is represented as a zero vector. \n",
    "        \"\"\"\n",
    "        tensor = [vocab.find(ch) + 1 for ch in string]\n",
    "        if stop:\n",
    "             tensor.append(len(vocab)+1)  # String + STOP\n",
    "        tensor = tf.one_hot(tensor,depth=len(vocab) + 2,on_value=1.0,off_value=0.0,axis=-1, dtype=tf.float32)\n",
    "        if start:\n",
    "            tensor=tf.concat([tf.zeros([1, len(vocab) + 2],dtype=tf.float32),tensor],axis=0)  # String + START\n",
    "        if sess is None:\n",
    "            with tf.Session() as sess:\n",
    "                nparray=tensor.eval()\n",
    "        elif type(sess) == tf.Session:\n",
    "            nparray = tensor.eval(session=sess)\n",
    "        else:\n",
    "            raise TypeError('\"sess\" must be {}, got {}'.format(tf.Session, type(sess)))    \n",
    "        return nparray\n",
    "\n",
    "    def decode(self, nparray, default=\"[UNKNOWN]\",start=\"[START]\",stop=\"[STOP]\",strip=False):\n",
    "        text_list = []\n",
    "        indices=np.argmax(nparray, axis=1)\n",
    "        for v, ch_i in zip(nparray,indices):\n",
    "            if np.all(v==0):\n",
    "                text_list.append(start if not strip else \"\")\n",
    "            elif ch_i==0:\n",
    "                text_list.append(default)\n",
    "            elif ch_i==len(self._vocab)+1:\n",
    "                text_list.append(stop if not strip else \"\")\n",
    "            else:\n",
    "                text_list.append(vocab[ch_i-1])\n",
    "        return \"\".join(text_list)\n",
    "    \n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self._dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test\n",
    "See how encoding and decoding work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text looks like:\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
      "Decoded text looks like:\n",
      "[START]Hello world[UNKNOWN][STOP]\n"
     ]
    }
   ],
   "source": [
    "test_codec=TextCodec(vocab)\n",
    "test_text_encoded=test_codec.encode(\"Hello world!\")\n",
    "print(\"Encoded text looks like:\\n{}\".format(test_text_encoded))\n",
    "test_text_decoded=test_codec.decode(nparray=test_text_encoded,strip=False)\n",
    "print(\"Decoded text looks like:\\n{}\".format(test_text_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded abstract from a total of 7201 theses.\n",
      "A sample text in the data set:\n",
      "The generalization error of deep neural networks via their classification margin is studied in this work, providing novel generalization error bounds that are independent of the network depth, thereby avoiding the common exponential depth-dependency which is unrealistic for current networks with hundreds of layers. We show that a large margin linear classifier operating at the output of a deep neural network induces a large classification margin at the input of the network, provided that the network preserves distances in directions normal to the decision boundary. The distance preservation is characterized by the average behaviour of the network's Jacobian matrix in the neighbourhood of the training samples. The introduced theory also leads to a margin preservation regularization scheme that outperforms weight decay both theoretically and empirically.\n",
      "Encoded text:\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
      "Decoded text:\n",
      "[START]The generalization error of deep neural networks via their classification margin is studied in this work, providing novel generalization error bounds that are independent of the network depth, thereby avoiding the common exponential depth-dependency which is unrealistic for current networks with hundreds of layers. We show that a large margin linear classifier operating at the output of a deep neural network induces a large classification margin at the input of the network, provided that the network preserves distances in directions normal to the decision boundary. The distance preservation is characterized by the average behaviour of the network's Jacobian matrix in the neighbourhood of the training samples. The introduced theory also leads to a margin preservation regularization scheme that outperforms weight decay both theoretically and empirically.[STOP]\n"
     ]
    }
   ],
   "source": [
    "with open(test_text_path, \"r\") as f:\n",
    "    raw_text_list = \"\".join(f.readlines()).split(\"\\n\")\n",
    "print(\"Loaded abstract from a total of {} theses.\".format(len(raw_text_list)))\n",
    "# See what we have loaded\n",
    "sample_text_no = random.randint(0, len(raw_text_list)-1)\n",
    "sample_text_raw = raw_text_list[sample_text_no]\n",
    "print(\"A sample text in the data set:\\n{}\".format(sample_text_raw))\n",
    "sample_text_encoded=test_codec.encode(sample_text_raw)\n",
    "print(\"Encoded text:\\n{}\".format(sample_text_encoded))\n",
    "print(\"Decoded text:\\n{}\".format(test_codec.decode(sample_text_encoded)))\n",
    "encoded_data = test_codec.encode(\"\\n\".join(raw_text_list), start=False, stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data, codec, batch_size, seq_length, reset_every):\n",
    "    if type(data) == str:\n",
    "        data=codec.encode(data, start=False, stop=False)\n",
    "    head = 0\n",
    "    reset_index = 0\n",
    "    batch = []\n",
    "    seq = []\n",
    "    increment = seq_length * reset_every - 1\n",
    "    extras = codec.encode(\"\", start=True, stop=True)\n",
    "    v_start, v_stop = extras[0: 1, :], extras[1: 2, :]\n",
    "    while head < np.shape(data)[0] or len(batch) == batch_size:\n",
    "        if len(batch) == batch_size:\n",
    "            batch = np.array(batch)\n",
    "            for offset in range(reset_every):\n",
    "                yield (batch[:, offset * seq_length: (offset + 1) * seq_length, :], \n",
    "                batch[:, offset * seq_length + 1: (offset + 1) * seq_length + 1, :])\n",
    "            batch = []\n",
    "        else:\n",
    "            seq = np.concatenate([v_start, data[head: head + increment, :], v_stop], axis=0)\n",
    "            if np.shape(seq)[0] == (increment + 2):\n",
    "                batch.append(seq)\n",
    "            head += increment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Reset\n",
      "Index of sub-sequence:\n",
      "0\n",
      "Sequence input:\n",
      "[START]In science and engineering, intelligent processing of complex signals such as images, sound or lang:\n",
      "Sequence output:\n",
      "In science and engineering, intelligent processing of complex signals such as images, sound or langu\n",
      "Index of sub-sequence:\n",
      "1\n",
      "Sequence input:\n",
      "[START]gically inspired. Hierarchical systems (or, more generally, nested systems) offer a way to generate:\n",
      "Sequence output:\n",
      "gically inspired. Hierarchical systems (or, more generally, nested systems) offer a way to generate \n",
      "Batch 1\n",
      "Index of sub-sequence:\n",
      "0\n",
      "Sequence input:\n",
      "uage is often performed by a parameterized hierarchy of nonlinear processing layers, sometimes biolo:\n",
      "Sequence output:\n",
      "age is often performed by a parameterized hierarchy of nonlinear processing layers, sometimes biolo[STOP]\n",
      "Index of sub-sequence:\n",
      "1\n",
      "Sequence input:\n",
      " complex mappings using simple stages. Each layer performs a different operation and achieves an eve:\n",
      "Sequence output:\n",
      "complex mappings using simple stages. Each layer performs a different operation and achieves an eve[STOP]\n",
      "Batch 2\n",
      "Reset\n",
      "Index of sub-sequence:\n",
      "0\n",
      "Sequence input:\n",
      "[START]r more sophisticated representation of the input, as, for example, in an deep artificial neural net:\n",
      "Sequence output:\n",
      "r more sophisticated representation of the input, as, for example, in an deep artificial neural netw\n",
      "Index of sub-sequence:\n",
      "1\n",
      "Sequence input:\n",
      "[START]ation of the parameters of all the layers and selection of an optimal architecture is widely consid:\n",
      "Sequence output:\n",
      "ation of the parameters of all the layers and selection of an optimal architecture is widely conside\n",
      "Batch 3\n",
      "Index of sub-sequence:\n",
      "0\n",
      "Sequence input:\n",
      "work, an object recognition cascade in computer vision or a speech front-end processing. Joint estim:\n",
      "Sequence output:\n",
      "ork, an object recognition cascade in computer vision or a speech front-end processing. Joint estim[STOP]\n",
      "Index of sub-sequence:\n",
      "1\n",
      "Sequence input:\n",
      "ered to be a difficult numerical nonconvex optimization problem, difficult to parallelize for execut:\n",
      "Sequence output:\n",
      "red to be a difficult numerical nonconvex optimization problem, difficult to parallelize for execut[STOP]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "reset_every = 2\n",
    "batch_size = 2\n",
    "batches = batch_generator(data=encoded_data, \n",
    "                               codec=test_codec, \n",
    "                               batch_size=batch_size, \n",
    "                               seq_length=seq_length, \n",
    "                               reset_every=reset_every)\n",
    "for (x, y), i in zip(batches, range(reset_every * 2)):\n",
    "    print(\"Batch {}\".format(i))\n",
    "    if (i % reset_every) == 0:\n",
    "        print(\"Reset\")\n",
    "    for j in range(batch_size):\n",
    "        decoded_x, decoded_y = test_codec.decode(x[j], strip=False), test_codec.decode(y[j], strip=False)\n",
    "        print(\"Index of sub-sequence:\\n{}\\nSequence input:\\n{}:\\nSequence output:\\n{}\".format(j, \n",
    "                                                                                          decoded_x, \n",
    "                                                                                          decoded_y))\n",
    "del seq_length, reset_every, batch_size, batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRNN(tf.nn.rnn_cell.RNNCell):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_hidden_layer, dtype=tf.float32):\n",
    "        super(tf.nn.rnn_cell.RNNCell, self).__init__(dtype=dtype)\n",
    "        assert type(input_dim) == int and input_dim > 0, \"Invalid input dimension. \"\n",
    "        self._input_dim = input_dim\n",
    "        assert type(num_hidden_layer) == int and num_hidden_layer > 0, \"Invalid number of hidden layer. \"\n",
    "        self._num_hidden_layer = num_hidden_layer\n",
    "        assert type(hidden_dim) == int and hidden_dim > 0, \"Invalid dimension of hidden states. \"\n",
    "        self._hidden_dim = hidden_dim\n",
    "        assert type(output_dim) == int and output_dim > 0, \"Invalid dimension of output dimension. \"\n",
    "        self._output_dim = output_dim\n",
    "        self._state_is_tuple = True\n",
    "        with tf.variable_scope(\"input_layer\"):\n",
    "            self._W_xh = tf.get_variable(\"W_xh\", shape=[self._input_dim, self._hidden_dim])\n",
    "            self._b_xh = tf.get_variable(\"b_xh\", shape=[self._hidden_dim])\n",
    "        with tf.variable_scope(\"rnn_layers\"):\n",
    "            self._cells = [tf.nn.rnn_cell.GRUCell(self._hidden_dim) for _ in range(num_hidden_layer)]\n",
    "        with tf.variable_scope(\"output_layer\"):\n",
    "            self._W_ho_list = [tf.get_variable(\"W_h{}o\".format(i), shape=[self._hidden_dim, self._output_dim])\n",
    "                               for i in range(num_hidden_layer)]\n",
    "            self._b_ho = tf.get_variable(\"b_ho\", shape=[self._output_dim])\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._output_dim\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return (self._hidden_dim,) * self._num_hidden_layer\n",
    "\n",
    "    def zero_state(self, batch_size, dtype):\n",
    "        if self._state_is_tuple:\n",
    "            return tuple(cell.zero_state(batch_size, dtype)for cell in self._cells)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Not implemented yet.\")\n",
    "\n",
    "    def __call__(self, _input, state, scope=None):\n",
    "        assert type(state) == tuple and len(state) == self._num_hidden_layer, \"state must be a tuple of size {}\".format(\n",
    "            self._num_hidden_layer)\n",
    "        hidden_layer_input = tf.matmul(_input, self._W_xh) + self._b_xh\n",
    "        prev_output = hidden_layer_input\n",
    "        final_state = []\n",
    "        output = None\n",
    "        for hidden_layer_index, hidden_cell in enumerate(self._cells):\n",
    "            with tf.variable_scope(\"cell_{}\".format(hidden_layer_index)):\n",
    "                new_output, new_state = hidden_cell(prev_output, state[hidden_layer_index])\n",
    "                prev_output = new_output + hidden_layer_input  # Should be included in variable scope of this layer or?\n",
    "                final_state.append(new_state)\n",
    "            _W_ho = self._W_ho_list[hidden_layer_index]\n",
    "            if output is None:\n",
    "                output = tf.matmul(new_output, _W_ho)\n",
    "            else:\n",
    "                output = output + tf.matmul(new_output, _W_ho)\n",
    "        output = tf.tanh(output + self._b_ho)\n",
    "        # output = tf.nn.relu(output)\n",
    "        final_state = tuple(final_state)\n",
    "        return output, final_state\n",
    "\n",
    "    def inspect_weights(self, sess):\n",
    "        val = self._W_xh.eval(sess)\n",
    "        print(\"W_xh:\\n{}\\nF-norm:\\n{}\".format(val, norm(val)))\n",
    "        val = self._b_xh.eval(sess)\n",
    "        print(\"b_xh:\\n{}\\nF-norm:\\n{}\".format(val, norm(val)))\n",
    "        for hidden_layer_index in range(self._num_hidden_layer):\n",
    "            val = self._W_ho_list[hidden_layer_index].eval(sess)\n",
    "            print(\"W_h{}o:\\n{}\\nF-norm:\\n{}\".format(hidden_layer_index, val, norm(val)))\n",
    "        val = self._b_ho.eval(sess)\n",
    "        print(\"b_ho:\\n{}\\nF-norm:\\n{}\".format(val, norm(val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an instance of the model and define the rest of the graph\n",
    "#### Thoughts\n",
    "If GRU is used, then the outputs of GRU shall not be directly used as desired output without further transforms. (e.g. A cell accpet 2 inputs, a state from the previous cell and the input of this cell(which is approximated by the state input), then the RNN cell can be treated as a normal feed forward network. \n",
    "\n",
    "**The proposal above is to be tested again due to the previous bug in training (Failed to feed the initial state given by the RNN output from last sequnce)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "input_dim = output_dim = test_codec.dim\n",
    "hidden_dim = 700\n",
    "num_hidden_layer = 3\n",
    "rnn_cell = DRNN(input_dim=input_dim, output_dim=output_dim, num_hidden_layer=num_hidden_layer, hidden_dim=hidden_dim)\n",
    "batch_size = 50\n",
    "init_state = tuple(tf.placeholder_with_default(input=tensor, \n",
    "                                         shape=[None, hidden_dim]) for tensor in rnn_cell.zero_state(\n",
    "    batch_size=batch_size, dtype=tf.float32))\n",
    "seq_input = tf.placeholder(name=\"batch_input\", shape=[None, None, input_dim], dtype=tf.float32)\n",
    "target_seq_output = tf.placeholder(name=\"target_batch_output\", shape=[None, None, output_dim], dtype=tf.float32)\n",
    "seq_output, final_states = tf.nn.dynamic_rnn(cell=rnn_cell,inputs=seq_input, \n",
    "                                                      initial_state=init_state, dtype=tf.float32)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target_seq_output, logits=seq_output))\n",
    "summary_op = tf.summary.scalar(tensor=loss, name=\"loss\")\n",
    "global_step = tf.get_variable(name=\"global_step\", initializer=0, trainable=False)\n",
    "lr = tf.get_variable(name=\"learning_rate\", initializer=1.0, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                    \n",
      "                                                                                                    \n",
      "dd                                                                                                  \n",
      "dd                                                                                                  \n",
      "fd                                                                                                  \n",
      "ff                                                                                                  \n",
      "fd                                                                                                  \n",
      "f                                                                                                   \n",
      "f                                                                                                   \n",
      "f                                                                                                   \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "f                                                                                                   \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "f                                                                                                   \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "n_epoch=50\n",
    "learning_rate=1e-3\n",
    "train_op=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss, global_step=global_step)\n",
    "print_every = 50\n",
    "save_every = 1000\n",
    "partition_size = 100\n",
    "logdir = os.path.normpath(\"./graphs\")\n",
    "seq_length = 100\n",
    "reset_every = 100\n",
    "visualize_every = 100\n",
    "learning_rate_decay = 0.9\n",
    "# batch_size has been specified when configuring the the tensors for initial states\n",
    "\n",
    "keep_checkpoint_every_n_hours = 0.5\n",
    "model_checkpoint_dir = os.path.normpath(\"./model_checkpoints\")\n",
    "model_checkpoint_path = os.path.join(model_checkpoint_dir, \"DRNN\")\n",
    "saver = tf.train.Saver(keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)\n",
    "batches = list(batch_generator(data=encoded_data, \n",
    "                               codec=test_codec, \n",
    "                               batch_size=batch_size, \n",
    "                               seq_length=seq_length, \n",
    "                               reset_every=reset_every))\n",
    "with tf.Session() as sess, tf.summary.FileWriter(logdir=logdir) as writer:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    feed_dict = dict()\n",
    "    states = None\n",
    "    sess.run(tf.assign(lr, learning_rate))\n",
    "    zero_states = sess.run(rnn_cell.zero_state(batch_size=1, dtype=tf.float32))\n",
    "    for epoch in range(n_epoch):\n",
    "        assert lr.eval(sess) > 0, \"learning_rate must be positive.\"\n",
    "        for i, (x, y) in enumerate(batches):\n",
    "            feed_dict = {seq_input: x, target_seq_output: y}\n",
    "            if (i % reset_every) != 0 and states is not None:\n",
    "                for j in range(len(init_state)):\n",
    "                    feed_dict[init_state[j]] = states[j]\n",
    "            _, summary, states, step = sess.run(fetches=[train_op, summary_op, final_states, global_step], \n",
    "                                                feed_dict=feed_dict)\n",
    "            writer.add_summary(summary=summary, global_step=step)\n",
    "            if ((step + 1) % save_every) == 0:\n",
    "                saver.save(sess=sess, save_path=model_checkpoint_path, global_step=step)\n",
    "            if (step % visualize_every) == 0:\n",
    "                feed_dict = {seq_input: x[:1, : , :]}\n",
    "                for key, value in zip(init_state, zero_states):\n",
    "                    feed_dict[key] = value\n",
    "                sample_output = sess.run(seq_output, feed_dict=feed_dict)\n",
    "                print(test_codec.decode(sample_output[0], strip=False))\n",
    "        sess.run(tf.assign(lr, lr.eval(sess) * learning_rate_decay))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test online inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_inference(cell, prime, sess, codec, \n",
    "                     input_tensor, \n",
    "                     init_state_tensor_tuple, \n",
    "                     output_tensor, \n",
    "                     final_state_tensor_tuple, \n",
    "                     length):\n",
    "    final_output = [prime]\n",
    "    zero_states = sess.run(cell.zero_state(batch_size=1, dtype=tf.float32))\n",
    "    feed_dict = {input_tensor: codec.encode(prime, start=True, stop=False)[np.newaxis, :, :]}  # prime\n",
    "    for init_state_tensor, init_state_value in zip(init_state_tensor_tuple, \n",
    "                                                   zero_states):\n",
    "        feed_dict[init_state_tensor] = init_state_value\n",
    "    output, final_states = sess.run([output_tensor, final_state_tensor_tuple], feed_dict=feed_dict)\n",
    "    final_output.append(codec.decode(output[0, -1:, :], strip=False))\n",
    "    for _ in range(length - len(prime)):\n",
    "        feed_dict = {input_tensor: codec.encode(final_output[-1], start=False, stop=False)[np.newaxis, :, :]}\n",
    "        for init_state_tensor, init_state_value in zip(init_state_tensor_tuple, final_states):\n",
    "            feed_dict[init_state_tensor] = init_state_value\n",
    "        output, final_states = sess.run([output_tensor, final_state_tensor_tuple], feed_dict=feed_dict)\n",
    "        final_output.append(codec.decode(output[0], strip=False))\n",
    "    return \"\".join(final_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    ckpt = saver.last_checkpoints\n",
    "    print(ckpt)\n",
    "    print(online_inference(rnn_cell, \"We propose\", \n",
    "                       sess, test_codec, seq_input, init_state, seq_output, final_states, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
