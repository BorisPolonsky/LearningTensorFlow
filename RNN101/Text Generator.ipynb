{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generator based on RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 84) (39, 84)\n"
     ]
    }
   ],
   "source": [
    "vocab = (\" $%'()+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "            \"\\\\^_abcdefghijklmnopqrstuvwxyz{|}\")\n",
    "TestText=\"Too young, too simple, sometimes naive. \"\n",
    "graphPath=r\".\\graphs\"\n",
    "num_step=len(TestText)-1\n",
    "state_size=100#Make it simple\n",
    "batchSize=1\n",
    "def Encode(string,name=None):\n",
    "    tensor=[vocab.find(ch)+1 for ch in string]\n",
    "    tensor = tf.one_hot(tensor, depth=len(vocab)+1, on_value=1.0, off_value=0.0, axis=-1, dtype=tf.float32, name=name)\n",
    "    with tf.Session() as sess:\n",
    "        nparray=tensor.eval()\n",
    "    return nparray\n",
    "def Decode(nparray):\n",
    "    return \"\".join([vocab[index-1] if index>0 else \"[INVALID]\" for index in np.argmax(nparray,axis=1)])\n",
    "X=Encode(TestText)\n",
    "Y=X[1:]\n",
    "X=X[:-1]\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"RNN\") as modelScope:\n",
    "    with tf.variable_scope(\"structure\") as structureScope:\n",
    "        inputs=tf.placeholder(dtype=tf.float32,shape=[None,len(vocab)+1])\n",
    "        outputs=tf.placeholder(dtype=tf.float32,shape=[None,len(vocab)+1])\n",
    "        cell=tf.contrib.rnn.GRUCell(num_units=state_size)\n",
    "        w=tf.get_variable(name=\"Weight_s_o\",shape=[state_size,len(vocab)+1],initializer=tf.truncated_normal_initializer())\n",
    "        b=tf.get_variable(name=\"Bias_s_o\",shape=[1,len(vocab)+1],initializer=tf.truncated_normal_initializer())\n",
    "        initState=cell.zero_state(batch_size=batchSize,dtype=tf.float32)\n",
    "        state=initState\n",
    "        netOutputs=[]\n",
    "        #Since the tf.nn.softmax_cross_entropy_with_logits() runs softmax internally, and \n",
    "        #I don't find another function to compute the cross entropy without internal softmax\n",
    "        #operations, so...\n",
    "        netVectsForLoss=[]\n",
    "        for i in range(num_step):\n",
    "            if(i>0):\n",
    "                structureScope.reuse_variables()\n",
    "            input_=tf.slice(input_=inputs,begin=[i,0],size=[1,-1])\n",
    "            output,state=cell(inputs=input_,state=state)\n",
    "            output=tf.add(tf.matmul(output,w),b)\n",
    "            netVectsForLoss.append(output)\n",
    "            output=tf.nn.softmax(output,name=\"Output\")\n",
    "            netOutputs.append(output)\n",
    "            input_=output\n",
    "        netOutputs=tf.concat(values=netOutputs,axis=0)\n",
    "        netVectsForLoss=tf.concat(values=netVectsForLoss,axis=0,name=\"vectForLoss\")\n",
    "    with tf.name_scope(\"training\"):\n",
    "        loss=tf.losses.softmax_cross_entropy(logits=netVectsForLoss,onehot_labels=outputs)\n",
    "        loss=tf.reduce_mean(loss,name=\"loss\")\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=0.001,name=\"optimizer\").minimize(loss)\n",
    "    with tf.name_scope(\"summary\") as scope:\n",
    "        summary_op=tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++m.''....cc'c'''''''''''''..c'cc..ccc\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer=tf.summary.FileWriter(logdir=graphPath,graph=sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result=sess.run(netOutputs,{inputs:X,outputs:Y})\n",
    "print(Decode(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  young, too simple, sometimes naive. n\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(2000):\n",
    "        sess.run(optimizer,feed_dict={inputs:X,outputs:Y})\n",
    "    result=sess.run(netOutputs,{inputs:X})\n",
    "print(Decode(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
