{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ..\\DataSet\\mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ..\\DataSet\\mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ..\\DataSet\\mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ..\\DataSet\\mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Number of training samples: 55000\n",
      "Number of test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.normpath(r\"../DataSet/mnist\")\n",
    "mnist_dataset=input_data.read_data_sets(dataset_path, one_hot=True)\n",
    "print(\"Number of training samples: {}\\nNumber of test samples: {}\".format(\n",
    "        mnist_dataset.train.num_examples, mnist_dataset.test.num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, noise_input_tensor, image_input_tensor, generator_hidden_dim, discriminator_hidden_dim):\n",
    "        self._noise_input = noise_input_tensor\n",
    "        self._image_input = image_input_tensor\n",
    "        with tf.variable_scope(\"generator\"):\n",
    "            g_o = self._generator_output = self._fnn(noise_input_tensor, generator_hidden_dim, image_input_tensor.shape[1])\n",
    "        with tf.variable_scope(\"discriminator\"):\n",
    "            d_o_real = self._discriminator_output_for_real_data = self._fnn(image_input_tensor, \n",
    "                                                                            discriminator_hidden_dim, 1)\n",
    "        with tf.variable_scope(\"discriminator\", reuse=True):  # Share weights and biases\n",
    "            d_o_fake = self._discriminator_output_for_synth = self._fnn(g_o, discriminator_hidden_dim, 1)\n",
    "    \n",
    "    def _fnn(self, input_tensor, hidden_dim, output_dim):\n",
    "        w = tf.get_variable(initializer=tf.truncated_normal_initializer, shape=[input_tensor.shape[1], hidden_dim], name=\"W_xh\")\n",
    "        b = tf.get_variable(initializer=tf.truncated_normal_initializer, shape=[hidden_dim], name=\"b_xh\")\n",
    "        hidden = tf.nn.relu(tf.add(tf.matmul(input_tensor, w), b))\n",
    "        w = tf.get_variable(initializer=tf.truncated_normal_initializer, shape=[hidden_dim, output_dim], name=\"W_ho\")\n",
    "        b = tf.get_variable(initializer=tf.truncated_normal_initializer, shape=[output_dim], name=\"b_ho\")\n",
    "        output = tf.add(tf.matmul(hidden, w), b)\n",
    "        return tf.sigmoid(output)\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def noise_input(self):\n",
    "        return self._noise_input\n",
    "    \n",
    "    @property\n",
    "    def image_input(self):\n",
    "        return self._image_input\n",
    "    \n",
    "    @property\n",
    "    def generator_output(self):\n",
    "        return self._generator_output\n",
    "\n",
    "    @property\n",
    "    def discriminator_output_from_generator(self):\n",
    "        return self._discriminator_output_for_synth\n",
    "    \n",
    "    @property\n",
    "    def discriminator_output_from_image_input(self):\n",
    "        return self._discriminator_output_for_real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise_dim = 128\n",
    "image_dim = 28*28\n",
    "generator_hidden_dim = 256\n",
    "discriminator_hidden_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "generator_input = tf.placeholder(shape=[None, noise_dim], dtype=tf.float32)\n",
    "discriminator_input = tf.placeholder(shape=[None, image_dim], dtype=tf.float32)\n",
    "gan = GAN(generator_input, discriminator_input, generator_hidden_dim, discriminator_hidden_dim)\n",
    "generator_loss = tf.reduce_mean(1.0-tf.log(gan.discriminator_output_from_generator))\n",
    "discriminator_loss = tf.reduce_mean(\n",
    "    tf.log(gan.discriminator_output_from_image_input)+tf.log(1.0-gan.discriminator_output_from_generator))\n",
    "g_train_op = tf.train.AdamOptimizer(learning_rate=2e-4).minimize(generator_loss)\n",
    "d_train_op = tf.train.AdamOptimizer(learning_rate=2e-4).minimize(discriminator_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epoch = 30\n",
    "batch_size = 50\n",
    "num_batch = int(mnist_dataset.train.num_examples/batch_size)\n",
    "k = 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_no in range(num_batch):\n",
    "            image_batch, _ = mnist_dataset.train.next_batch(batch_size) # discard the labels\n",
    "            # Train the discriminator network\n",
    "            for k in range(5):\n",
    "                noise_batch = np.random.uniform(-1.0, 1.0, size=[batch_size, noise_dim])\n",
    "                feed_dict = {gan.image_input: image_batch, gan.noise_input: noise_batch}\n",
    "                sess.run(d_train_op, feed_dict=feed_dict)\n",
    "            # Train the generator\n",
    "            noise_batch = np.random.uniform(-1.0, 1.0, size=[batch_size, noise_dim])\n",
    "            feed_dict = {gan.image_input: image_batch, gan.noise_input: noise_batch}\n",
    "            _, g_loss, d_loss = sess.run([g_train_op, generator_loss, discriminator_loss], feed_dict=feed_dict)\n",
    "            print(\"Generator loss:{}\\nDiscriminator loss:{}\".format(g_loss, d_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
